---
title: "Cyclistic Bike share"
author: "Muzzammil khan"
date: "18 March 2023"
output:
  html_document: 
    toc_float: yes
    toc_depth: 2
    theme: cerulean
    number_sections: yes
    toc: yes
subtitle: Google data analytics capstone project
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
``` 
# Introduction
This is my first project, which is the Google data analytics certificate capstone project named "Cyclistic bike share". For the analysis purpose i will use R studio. I will work for a fictional company, **Cyclistic**, and meet different characters and team members. In order to answer the key business questions, I will follow the steps of the data analysis process as shown below: 

* Ask

* Prepare

* Process

* Analyze

* Share

* Act

## Scenario
You are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve your recommendations, so they must be backed up with compelling data insights and professional data visualizations.

## About the company
In 2016, Cyclistic launched a successful bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that are geotracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.
Until now, Cyclistic’s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes, and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.
Cyclistic’s finance analysts have concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, Lily Moreno (marketing director) believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, Moreno believes there is a very good chance to convert casual riders into members. She notes that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.
Moreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics. Moreno and her team are interested in analyzing the Cyclistic historical bike trip data to identify trends.

# Ask
A clear statement of the business task:
Cyclistic finance team concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, They believe that maximising the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, they believe there is a very good chance to convert casual riders into members.
They note that casual riders are already aware of the Cyclistic program and have chosen Cyclistic for their mobility needs.The company has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why casual riders would buy a membership, and how digital media could affect their marketing tactics.
Moreno has assigned you the first question to answer:

**How do annual members and casual riders use Cyclistic bikes differently?**

## Key stakeholders

* Cyclistic marketing analytics team: A team of data analysts who are responsible for collecting, analyzing, and reporting data that helps guide Cyclistic marketing strategy. I am hypothetically part of the analytics team as a junior data analyst.

* Executive team: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.

* Lily moreno: The director of marketing and your manager. Moreno is responsible for the development of campaigns and initiatives to promote the bike-share program. These may include email, social media, and other channels.

# Prepare

At this phase asking relevant questions are key to preparing the data before moving to process and analyze phase:

Addressing data location, organisation, credibility, privacy and integrity

Q1: Where is your data located?

Ans: We will use Cyclistic’s historical trip data to analyse and identify trends. The datasets have a different name because Cyclistic is a fictional company. For the purposes of this case study, the datasets are appropriate and will enable us to answer the business questions. (The previous 12 months data is made available by Cyclistic bike share company and the link is as follows: https://divvy-tripdata.s3.amazonaws.com/index.html ) 

Q2: How is the data organised?

Ans: The data is organised as monthly rider data in csv file format. The data contains following columns: data contain ride_id, rideable_type, start_station_name, start_station_id, end_station_name, end_station_id, member_casual,start_lat, start_lng, end_lat, end_lng,started_at(day and time), ended_at(day and time).

Q3: Are there issues with bias or credibility in this data? Does your data ROCCC?

Ans: As we know that ROCCC stands for reliable, original, comprehensive, current and cited. As data was collected by cyclistic bike sharing company, the data collected is reliable, original, formatted in csv file format for each month, current and cited.

Q4: How are you addressing licensing, privacy, security, and accessibility?

Ans: This is public data that we can use to explore how different customer types are using Cyclistic bikes. But note that data-privacy issues prohibit us from using riders’ personally identifiable information. Therefore we won’t have the information related to customers credit card numbers, names and their addresses. (The data has been made available by Motivate International Inc. under this license.) 

Q5: How did you verify the data’s integrity?

Ans: I have checked the data for errors and cleaning/manipulating the data to verify its integrity since it is crucial to verify the data’s integrity otherwise our whole analysis would go wrong.

**Let's start preparing our data:**

## Install packages and load
```{r}
install.packages("tidyverse", repos='http://cran.us.r-project.org')
install.packages("janitor", repos='http://cran.us.r-project.org')
install.packages("dplyr", repos='http://cran.us.r-project.org')
install.packages("ggmap", repos='http://cran.us.r-project.org')
install.packages("skimr", repos='http://cran.us.r-project.org')
install.packages("lubridate", repos='http://cran.us.r-project.org')
install.packages("ggplot2", repos='http://cran.us.r-project.org')
install.packages("readr", repos='http://cran.us.r-project.org')
install.packages("googlesheets4", repos='http://cran.us.r-project.org', dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages("knitr", repos='http://cran.us.r-project.org')
install.packages("imager", repos='http://cran.us.r-project.org')
install.packages("rmarkdown", repos='http://cran.us.r-project.org')

## loading the packages
library(tidyverse)
library(janitor)
library(dplyr)
library(ggmap)
library(skimr)
library(lubridate)
library(ggplot2)
library(readr)
library(googlesheets4)
library(knitr)
library(imager)
library(rmarkdown)
getwd()
```

## Importing data in Rstudio
```{r}
Jan22 <- read_csv("202201-divvy-tripdata.csv")
Feb22 <- read_csv("202202-divvy-tripdata.csv")
Mar22 <- read_csv("202203-divvy-tripdata.csv")
Apr22 <- read_csv("202204-divvy-tripdata.csv")
May22 <- read_csv("202205-divvy-tripdata.csv")
Jun22 <- read_csv("202206-divvy-tripdata.csv")
Jul22 <- read_csv("202207-divvy-tripdata.csv")
Aug22 <- read_csv("202208-divvy-tripdata.csv")
Sep22 <- read_csv("202209-divvy-publictripdata.csv")
Oct22 <- read_csv("202210-divvy-tripdata.csv")
Nov22 <- read_csv("202211-divvy-tripdata.csv")
Dec22 <- read_csv("202212-divvy-tripdata.csv")
```

## Checking columns consistency
```{r}
colnames(Jan22)
colnames(Feb22)
colnames(Mar22)
colnames(Apr22)
colnames(May22)
colnames(Jun22)
colnames(Jul22)
colnames(Aug22)
colnames(Sep22)
colnames(Oct22)
colnames(Sep22)
colnames(Oct22)
colnames(Nov22)
colnames(Dec22)

## Checking data structure
str(Jan22)
```
```{r, comment=NA, eval=FALSE}
str(Feb22)
str(Mar22)
str(Apr22)
str(May22)
str(Jun22)  
str(Jul22)
str(Aug22)
str(Sep22)
str(Oct22)
str(Nov22)
str(Dec22)
```

## Combine datasets
```{r}
## Using rbind function to combine all datasets into large one dataframe
bike_rides <- rbind(Jan22, Feb22, Mar22, Apr22, May22, Jun22, Jul22, Aug22, Sep22, Oct22, Nov22, Dec22)
## Removing individual data sets to free up memory
rm(Jan22, Feb22, Mar22, Apr22, May22, Jun22, Jul22, Aug22, Sep22, Oct22, Nov22, Dec22)
```

# Process
**Key tasks**

1. Check the data for errors.
2. Choose your tools.
3. Transform the data so you can work with it effectively.
4. Document the cleaning process.

**Deliverable**

Documentation of any cleaning or manipulation of data.

*Let's dive into processing our data*

## Inspecting the data frame
```{r}
head(bike_rides)
class(bike_rides)
dim(bike_rides)
colSums(is.na(bike_rides))
summary(is.na(bike_rides))
colnames(bike_rides)
summary(bike_rides)
```

## Processing the data frame
```{r}
# Removing the duplicates
bike_rides %>% distinct()
dim(bike_rides)
str(bike_rides)
```

### Create date variables
```{r}
bike_rides <- bike_rides %>% mutate(start_date = as.Date(bike_rides$started_at))
bike_rides <- bike_rides %>% mutate(end_date = as.Date(bike_rides$ended_at))
bike_rides <- bike_rides %>%
  mutate(
    Start_Yr = year(started_at),
    Start_Mth = month(started_at),
    Start_Day = wday(started_at),
    Start_Hr = hour(started_at)
  )
bike_rides <- bike_rides %>%
  mutate(
    End_Yr = year(ended_at),
    End_Mth = month(ended_at),
    End_Day = wday(ended_at),
    End_Hr = hour(ended_at))
```

### Adding the Seasons column
```{r}
bike_rides <- bike_rides %>% mutate(season = recode(Start_Mth,
                                                    `12` = "Winter",
                                                    `1` = "Winter",
                                                    `2` = "Winter",
                                                    `3` = "Spring",
                                                    `4` = "Spring",
                                                    `5` = "Spring",
                                                    `6` = "Summer",
                                                    `7` = "Summer",
                                                    `8` = "Summer",
                                                    `9` = "Fall",
                                                    `10` = "Fall",
                                                    `11` = "Fall"))
```
```{r}
dim(bike_rides)
```

### Creating columns ride_length_sec, ride_length_min and ride_length_hr
```{r}
bike_rides %>% filter(ended_at < started_at) %>% count()
bike_rides %>% filter(ended_at > started_at) %>% count()
# creating column ride_length_sec (in seconds)
bike_rides <- bike_rides %>%
  mutate(ride_length_sec = ended_at - started_at)
# creating column ride_length_min (in minutes)
bike_rides <- bike_rides %>%
  mutate(ride_length_min = difftime(ended_at,started_at,units='mins',2))
# creating column ride_length_hour (in hours)
bike_rides$ride_length_hour <- round(as.numeric(difftime(bike_rides$ended_at, bike_rides$started_at, units = "hours")), 2)
```
```{r}
str(bike_rides)
```

### Exploring ride_length_min (in minutes) column in depth
```{r}
sum(bike_rides$ride_length_min > 1440)
```
Less than 1 minute
```{r}
sum(bike_rides$ride_length_min < 1)
```
To confirm any negative figure, use less than 0
```{r}
sum(bike_rides$ride_length_min < 0)
```
Greater than 6 hours(360 mins)
```{r}
sum(bike_rides$ride_length_min > 360)
```
Removing ride_length_min > 24 hours and < 0 mins
```{r}
bike_rides <- bike_rides %>% 
  filter(ride_length_min >= 0 & ride_length_min <= 1440)
dim(bike_rides)
```

### Renaming the columns
```{r}
bike_rides <- rename(bike_rides, "bike_type" = "rideable_type", "user_type" = "member_casual")
```

## Addressing missing values
```{r}
# checking if Na values in start and end_station_id pertains to any user and bike type
bike_rides %>% filter(is.na(start_station_id)) %>%
  count(start_station_id, start_station_name, bike_type, user_type)
# we can see here that electric bikes with mixed user types are linked to na values in start station id
# we can see here that electric bikes are associated with na values in start station id codes
```

```{r}
# checking for end station id codes
bike_rides %>% filter(is.na(end_station_id)) %>%
  count(end_station_id, end_station_name, bike_type, user_type)
# here three different bike types with both users pertains to na values
```
```{r}
str(bike_rides)
```

### Checking the missing data (Na) and removing it
```{r}
summary(is.na(bike_rides))
colSums(is.na(bike_rides))
```

Since start/end station name and id and ending lat/lng data is immaterial, i would proceed removing them
```{r}
bike_rides <- bike_rides %>% filter(is.na(start_station_name)==F)
bike_rides <- bike_rides %>% filter(is.na(end_station_name)==F)
bike_rides <- bike_rides %>% filter(is.na(end_lat)==F)
colSums(is.na(bike_rides))
```

Converting bike_type and user_type as factors
```{r}
bike_rides$bike_type <- as.factor(bike_rides$bike_type)
bike_rides$user_type <- as.factor(bike_rides$user_type)

str(bike_rides)
```

# Analyse 
**Key tasks**

1. Aggregate your data so it’s useful and accessible.
2. Organize and format your data.
3. Perform calculations.
4. Identify trends and relationships.

**Deliverable**

A summary of your analysis

*Let's dive into analyzing our data*

## Members vs casual riders
At this phase, we will try differentiating member vs. casual riders to look for trends and patterns

### Descriptive analysis
Let's start with conducting descriptive analysis
```{r}
# Removing rides greater than 24 hours as it is unlikely and less than 1 mins as they could be false start
# removing ride_length_min > 24 hours and < 1 mins
bike_rides <- bike_rides %>% filter(ride_length_min >= 1, ride_length_min < 1440)
```
Let's see mean, median, max and min of our ride_length_min (minutes)
```{r}
bike_rides %>%
  summarise(avg_ride_length = mean(ride_length_min), median_length = median(ride_length_min),
            max_length= max(ride_length_min), min_length = min(ride_length_min))
```
Let's summarise the descriptive stats by user_type
```{r}
bike_rides %>% group_by(user_type) %>% 
  summarise(avg_ride_length = mean(ride_length_min), median_length = median(ride_length_min),
                                                 max_length= max(ride_length_min), min_length = min(ride_length_min))
# it can be seen that casual riders have almost double the average ride length compared to members and took longer rides than members
```
Let's see Total number of casual and member users
```{r}
bike_rides %>%
  select(user_type) %>%
  group_by(user_type) %>%
  count() %>%
  arrange()
# there are 830,371 more member riders compared to casual riders
```
Let's visualize this data using a plot
```{r}
ggplot(data = bike_rides) + geom_bar(mapping = aes(x = user_type, fill = user_type)) +
  labs(title = "No of users", x = "user type", y = "Count")
# as can be seen there are more members compared to casual bike riders
```

Let's see count of each bike type
```{r}
bike_rides %>%
  group_by(bike_type) %>% 
  summarise(count = length(ride_id))
```

Let's also visualize usage of different bike types by the users
```{r}
ggplot(data = bike_rides) + geom_bar(mapping = aes(x = bike_type, fill = bike_type)) + facet_wrap(~user_type) +
  labs(title = "Bike type usage", x = "Bike_Type", y = "Count")
# members never used docked bikes while used mostly classic bikes
# casual riders used docked bikes alongside classic and electric bikes
```

### Analysing ride_length_min (in minutes) column thoroughly
Let's see average ride length by user type
```{r}
aggregate(bike_rides$ride_length_min ~ bike_rides$user_type, FUN = mean)
# shows that casual riders had taken twice more rides compared to members
```

### Summarising ride_length_min column
Let's summarise ride_length_min by looking at ranges of minutes to see if anything stands out
```{r}
bike_rides %>%
  group_by(user_type) %>%
  summarize("<=5min" = sum(ride_length_min <=5),
            "<=15min" = sum(ride_length_min <=15),
            "<=30min" = sum(ride_length_min <=30),
            "<=45min" = sum(ride_length_min <=45),
            "<=60min" = sum(ride_length_min <=60),
            ">2hrs" = sum(ride_length_min >120),
            ">4hrs" = sum(ride_length_min >240),
            ">6hrs" = sum(ride_length_min >360),) 
```

### Rides interval analysis
I have done analysis in Google sheets to see how much % of rides data lies in each ride interval
```{r}
df <- read.csv("ridesanalysis.csv",check.names = F)
view(df)
kable(df[1:5, ], caption = "Rides interval analysis.")
# Key takeaways
# 100% of all the rides taken are 60 mins or less
# 73% of all the rides taken are 45 mins or less
# 23% of all the rides taken are 15 mins or less
# this data will greatly assist cyclistic in assesing the strategic direction
```

Let's see the user type by count and percentage
```{r}
bike_rides %>%
  group_by(user_type) %>%
  summarise(count = n(), Percentage = n()/nrow(bike_rides)*100)
```

Let's visualize user type by total rides and by bike type in a plot
```{r}
bike_rides %>%
  group_by(user_type, bike_type) %>%
  summarise(count = n()) %>%
  ggplot(aes(x=user_type, y=count, fill=bike_type)) +
  geom_bar(stat="identity", width = 0.4) +
  labs(x="Bike Type", y="Number of Rides", title = "Total Rides by user type and bike type")
# only casual riders used docked bikes whereas members used only classic and electric bikes
```

## Analysing rides in depth
***I will analyse rides by users in sequence starting with minutes, hours, days, months and finally seasons.***

Let's create different ride length intervals alongside ride length interval column and then visualize
```{r}
bike_rides <- bike_rides %>% mutate(ride_length_inter = case_when(
  ride_length_min <9.99 ~ "< 10 min",
  ride_length_min <14.99 ~ "< 15 min",
  ride_length_min >=15 & ride_length_min <=20.99 ~ "15-20 min",
  ride_length_min >=21 & ride_length_min <=30.99  ~ "21-30 min",
  ride_length_min >=31 & ride_length_min <=60.99  ~ "31-60 min",
  ride_length_min >=60 & ride_length_min <=120.99  ~ "61-120 min",
  ride_length_min >=121 & ride_length_min <=240.99  ~ "121-240 min",
  ride_length_min >=241  ~ "241+ min"))
```

### Analysing rides by users in minutes
Let's visualize the total rides taken by user type and ride length intervals
```{r}
bike_rides %>%
  group_by(user_type, ride_length_inter) %>%
  summarise(count = n()) %>%
  ggplot(aes(x=factor(ride_length_inter, level = c("< 10 min", "< 15 min", "15-20 min" ,"21-30 min",   "31-60 min", "61-120 min", "121-240 min", "241+ min")), y=count, fill=user_type)) +
  geom_col(position = "dodge") +
  labs(x="Ride Length intervals", y="Number of Rides", title = "Total Rides by user type and ride length intervals")
# key takeaways
# member riders took mostly shorter rides i.e. between 1-20 min rides
# casual riders took longer rides compared to members
```

Let's see average or mean of ride length for "< 10 min" interval
```{r}
bike_rides %>% filter(ride_length_inter == "< 10 min") %>%
  group_by(user_type) %>%
  summarize(avg_ride_length=mean(ride_length_min))
```

Now average or mean of "< 20min" intervals
```{r}
bike_rides %>% filter(ride_length_inter == "< 15 min" | ride_length_inter== "15-20 min") %>%
  group_by(user_type) %>%
  summarize(avg_ride_length=mean(ride_length_min))
# casual riders on average took longer rides under the 10 min and 15-20 min intervals
```

### Analysing rides by hour of day
Let's visualize the demand for bikes based on hour of day
```{r}
bike_rides %>%
  ggplot(aes(Start_Hr, fill= user_type)) +
  labs(x="Day Hour", title="Bike demand by day hour") +
  geom_bar()
# Key takeaways
# most demand for bikes is between 7am-8am and in the evening between 4pm-6pm for both user types
```

Let's visualize total number of rides by users based on day hour
```{r}
bike_rides %>% 
  group_by(user_type, Start_Hr) %>% 
  summarise(count = n()) %>%  
  arrange(user_type, Start_Hr) %>% 
  ggplot(aes(x=factor(Start_Hr, level= c(6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5)), 
  y=count, fill=user_type)) + geom_col(position = "dodge") +
  labs(x="Day hour", y="No of Rides", title = "Total rides by users vs. day hour")
# Key takeaways
# for both casual and member riders most number of rides are between 16pm-18pm
```

Let's also visualize average ride length in mins by users based on day hour
```{r}
bike_rides %>% 
  group_by(user_type, Start_Hr) %>% 
  summarise(count = n(), average_ride_length=mean(ride_length_min)) %>% 
  arrange(user_type, Start_Hr) %>% 
  ggplot(aes(x=factor(Start_Hr, level= c(6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,0,1,2,3,4,5)),
  y=average_ride_length, fill=user_type)) + geom_col(position = "dodge") +
  labs(x="Day hour", y="Avg ride length (in mins)", title = "Average rides by users and day hour")
# Key takeaways
# casual riders took longer rides on average in mins peaking from 10am-3pm
# member riders have consistent average rides in mins throughout the day
```

### Analysing rides by day time
Let's add day time column
```{r}
bike_rides <- bike_rides %>% mutate(day_time = case_when(
  Start_Hr >= 6 & Start_Hr < 9 ~ "Early Morning",
  Start_Hr >= 9 & Start_Hr < 12 ~ "Mid Morning",
  Start_Hr >= 12 & Start_Hr < 18  ~ "Afternoon",
  Start_Hr >= 18 & Start_Hr <= 23  ~ "Evening",
  Start_Hr >= 0 & Start_Hr < 3  ~ "Early Night",
  Start_Hr >= 3 & Start_Hr < 6  ~ "Late Night"))
bike_rides <- bike_rides %>% relocate(day_time, .before = season)
```

Let's visualize total number of rides by users based on day time
```{r}
axis_labels <- c("Early Morning \n6am-9am", "Mid Morning \n9am-12pm", "Afternoon \n12pm-6pm", "Evening \n6pm-11pm", "Early Night \n11pm-3am", "late Night \n3am-6am")
bike_rides %>% 
  group_by(user_type, day_time) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x=factor(day_time, level= c("Early Morning", "Mid Morning", "Afternoon", "Evening", "Early Night", "Late Night")),
             y=count, fill=user_type)) + 
  geom_col(position = "dodge", width = 0.4) + 
  labs(x="Day time", y="Total Rides", title = "Total Rides by user type vs. Day time") +
  scale_x_discrete(labels = axis_labels)
# Key takeaways
# members took most number of rides early morning compared to casual riders
# both users took most rides in the afternoon and evening time
```

Let's now visualize average ride length in mins by users based on day time
```{r}
axis_labels <- c("Early Morning \n6am-9am", "Mid Morning \n9am-12pm", "Afternoon \n12pm-6pm", "Evening \n6pm-11pm", "Early Night \n11pm-3am", "late Night \n3am-6am")
bike_rides %>% 
  group_by(user_type, day_time) %>% 
  summarise(count = n(), average_ride_length=mean(ride_length_min)) %>% 
  ggplot(aes(x=factor(day_time, level= c("Early Morning", "Mid Morning", "Afternoon", "Evening", "Early Night", "Late Night")),
             y=average_ride_length, fill=user_type)) + 
  geom_col(position = "dodge", width = 0.4) + 
  labs(x="Day time", y="Avg ride length in mins", title = "Avg Ride length in mins by users vs. Day time") +
  scale_x_discrete(labels = axis_labels)
# Key takeaways
# casual riders on average took longer rides in minutes than members peaking in mid-morning and afternoon
```

### Analysing rides by days
Let's convert month and day data from numerical to categorical for analysis based on week day
```{r}
bike_rides <- bike_rides %>%
  mutate(Start_Mth = format(as.Date(started_at), "%B")) %>%
  mutate(Start_Day = format(as.Date(started_at), "%A")) %>%
  mutate(End_Mth = format(as.Date(ended_at), "%B")) %>%
  mutate(End_Day = format(as.Date(ended_at), "%A"))
str(bike_rides)
```

Let's order start_day column before proceeding to further analysis
```{r}
bike_rides$Start_Day <- ordered(bike_rides$Start_Day, 
                                      levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

Let's see the average ride length in mins during only weekdays for both users
```{r}
bike_rides  %>% filter(Start_Day != "Saturday" &
                         Start_Day != "Sunday") %>% group_by(user_type, Start_Hr) %>% 
  summarise(avg_ride_length_min = mean(ride_length_min),.groups="drop") %>% 
  ggplot(aes(x = Start_Hr, y = avg_ride_length_min)) + geom_point() + 
  geom_line(aes(group = user_type, colour = user_type)) + ylim(0, NA) + 
  ggtitle("Average ride length by hour on weekdays") + 
  labs(x = "Hour", y = "Avg ride length in mins")
# Key takeaways
# casual riders against members took longer rides on average during weekdays, peaking between 10am-12am
```

Let's now see average ride length by users during weekends only
```{r}
bike_rides  %>% filter(Start_Day == "Saturday" |
                         Start_Day == "Sunday") %>% group_by(user_type, Start_Hr) %>% 
  summarise(avg_ride_length_min = mean(ride_length_min),.groups="drop") %>% 
  ggplot(aes(x = Start_Hr, y = avg_ride_length_min)) + geom_point() + 
  geom_line(aes(group = user_type, colour = user_type)) + ylim(0, NA) + 
  ggtitle("Average ride length by hour on weekends") + 
  labs(x = "Hour", y = "Avg ride length in mins")
# Key takeaways
# on weekends casual riders took longer rides on average in mins peaking between 10am-15pm
```

Let's analyse total rides and average rides taken by users based on the week day
```{r}
bike_rides %>%
  group_by(user_type, Start_Day) %>%
  summarise(number_of_rides = n()
            ,avg_ride_length_min = mean(ride_length_min),.groups="drop") %>%
  arrange(user_type, Start_Day)
```

Let's see average rides by users based on week day side by side
```{r}
aggregate(bike_rides$ride_length_min ~ bike_rides$user_type + bike_rides$Start_Day, FUN = mean)
# Key takeaways
# casual riders took more rides on the weekends where average ride length is also much higher than members
# member riders have more number of rides on the weekdays which could mean commuting to work etc.
```

Let's visualize number of rides taken by users based on the day of week
```{r}
bike_rides %>%
  group_by(user_type, Start_Day) %>%
  summarise(number_of_rides = n(), .groups="drop") %>%
  arrange(user_type, Start_Day)  %>%
  ggplot(aes(x = Start_Day, y = number_of_rides, fill = user_type)) +
  labs(x="Week_day", y="number_of_rides", title ="Rides by users vs. Day of the week") +
  geom_col(width=0.4, position = position_dodge(width=0.4)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```

Let's visualize the same by incorporating geom_point and line
```{r}
bike_rides %>%
  group_by(user_type, Start_Day) %>%
  summarise(number_of_rides = n(), .groups="drop") %>%
  arrange(user_type, Start_Day)  %>%
  ggplot(aes(x=factor(Start_Day, level= c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")), 
             y=number_of_rides, color = user_type)) +
  geom_point() + geom_line(aes(group = user_type)) +
  labs(x="Week_day", y="number_of_rides", title ="Rides by users vs. Day of the week") +
  ylim(0, NA)
```

Let's now visualize average rides taken by users based on week day
```{r}
bike_rides %>%  
  group_by(user_type, Start_Day) %>% 
  summarise(average_ride_length = mean(ride_length_min), .groups="drop") %>%
  ggplot(aes(x = Start_Day, y = average_ride_length, fill = user_type)) +
  geom_col(width=0.4, position = position_dodge(width=0.4)) + 
  labs(x="Week_day", y="Avg_ride_length_mins", title ="Average ride length by users Vs. Week day")
# Key takeaways
# casual riders on average took longer rides compared to members fluctuating between 20-25 mins
# members have consistent average rides throughout week i.e. between 10-15 min rides
# casual riders average ride length on weekends is much higher i.e. greater than 25 mins
```

### Analysing rides by months
Let's visualize total rides by users in each month
```{r}
# first let's order the months data
bike_rides$Start_Mth <- ordered(bike_rides$Start_Mth, 
                                levels=c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"))
bike_rides %>%  
  group_by(user_type, Start_Mth) %>% 
  summarise(number_of_rides = n(),.groups="drop") %>% 
  arrange(user_type, Start_Mth)  %>% 
  ggplot(aes(x = Start_Mth, y = number_of_rides, fill = user_type)) +
  labs(title ="Total number of rides by users Vs. Month", x = "Month", y= "Total Rides") +
  theme(axis.text.x = element_text(angle = 50)) +
  geom_col(width=0.4, position = position_dodge(width=0.4)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
# Key takeaways
# members compared to casual riders have higher number of rides throughout the year
# casual riders took most number of rides in the summer season i.e. June and July
# members took most number of rides from May till September 
```

Let's visualize average ride length in mins for both users by month
```{r}
bike_rides %>%  
  group_by(user_type, Start_Mth) %>% 
  summarise(average_ride_length = mean(ride_length_min),.groups="drop") %>%
  arrange(user_type, Start_Mth)  %>% 
  ggplot(aes(x = Start_Mth, y = average_ride_length, fill = user_type)) +
  labs(title ="Average ride length by users Vs. Month", x = "Month", y= "Avg ride length in mins") +
  theme(axis.text.x = element_text(angle = 50)) +
  geom_col(width=0.4, position = position_dodge(width=0.4)) +
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
# Key takeaways
# casual riders have more number of rides on average compared to members
# casual riders took most rides on average in minutes in the months March, April and May
# members took most number of rides on average in the months from May till September
```

Let's visualize Total rides by each user type in each month side by side
```{r}
bike_rides %>%
  group_by(user_type, Start_Mth) %>%
  summarise(number_of_rides = n(), .groups="drop") %>%
  arrange(user_type, Start_Mth)  %>%
  ggplot(aes(x = Start_Mth, y = number_of_rides,  fill = Start_Mth)) + 
  geom_col() + facet_wrap(~user_type) + 
  labs(title = "Total Rides per Month", x = "Month", y = "Total rides") +
  theme(axis.text.x = element_text(size = 4, angle = 20))
# Key takeaways
# casual riders had most number of rides in the summer period from June-August
# members have most number of rides from May-September as our previous analysis suggested
```

### Analysing rides by seasons
Finally let's now visualize rides by users based on seasons of the year
```{r}
bike_rides %>% 
  group_by(user_type, season) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x=factor(season, level= c("Spring", "Summer", "Fall", "Winter")), y=count, fill=user_type)) + 
  geom_col(position = "dodge", width = 0.5) + 
  labs(x="Season", y="Total Rides", title = "Total Rides by user type vs. season")
# Key takeaways
# members have more bike rides in total compares to casual riders in every season of the year
# casual and member riders have most rides in the summer season
# member riders used most bikes in the summer and fall season 
```



## Analysing bike stations
Let's now focus our analysis to bike start and end stations
```{r}
# counting top 10 popular starting stations for casual riders
bike_rides %>% 
  filter(!(is.na(start_station_name))) %>% 
  filter(user_type == "casual") %>% 
  group_by(start_station_name) %>% 
  summarize(count=n()) %>% 
  arrange(-count) %>% top_n(10)
# counting top 10 popular starting stations for members
bike_rides %>% 
  filter(!(is.na(start_station_name))) %>% 
  filter(user_type == "member") %>% 
  group_by(start_station_name) %>% 
  summarize(count=n()) %>% 
  arrange(-count) %>% top_n(10)
```

### Visualising top 10 popular starting stations for casual riders
```{r}
bike_rides %>% 
  filter(!(is.na(start_station_name))) %>% 
  filter(user_type == "casual") %>% 
  group_by(start_station_name) %>% 
  summarize(count=n()) %>% 
  arrange(-count) %>% top_n(10) %>%
  mutate(start_station_name= fct_reorder(start_station_name, count)) %>% 
  ggplot(aes(x=start_station_name, y=count, fill=count)) +
  geom_bar(stat = "identity") + coord_flip() + scale_fill_gradient(low="blue", high="red") +
  labs(x="Start Station Name", y="No of rides", title="Top 10 starting stations for casual riders")
```

### Visualising top 10 popular starting stations for members
```{r}
bike_rides %>% 
  filter(!(is.na(start_station_name))) %>% 
  filter(user_type == "member") %>% 
  group_by(start_station_name) %>% 
  summarize(count=n()) %>% 
  arrange(-count) %>% top_n(10) %>%
  mutate(start_station_name= fct_reorder(start_station_name, count)) %>% 
  ggplot(aes(x=start_station_name, y=count, fill=count)) +
  geom_bar(stat = "identity") + coord_flip() + scale_fill_gradient(low="blue", high="red") +
  labs(x="Start Station Name", y="No of rides", title="Top 10 starting stations for member riders")
# Key takeaways
# casual riders, most popular starting station is Streeter Dr & Grand Ave 
# member riders, most popular starting station is Kingsbury St & Kinzie St 
```


### Analysing bike ending stations
Confirm if the ending stations for users are also the same as starting stations
```{r}
bike_rides %>% 
  filter(!(is.na(end_station_name))) %>% 
  filter(user_type == "casual") %>% 
  group_by(end_station_name) %>% 
  summarize(count=n()) %>% 
  arrange(-count) %>% top_n(10) %>%
  mutate(end_station_name= fct_reorder(end_station_name, count)) %>% 
  ggplot(aes(x=end_station_name, y=count, fill=count)) +
  geom_bar(stat = "identity") + coord_flip() + scale_fill_gradient(low="blue", high="red") +
  labs(x="Ending Station Name", y="No of rides", title="Top 10 ending stations for casual riders")
```
```{r}
bike_rides %>% 
  filter(!(is.na(end_station_name))) %>% 
  filter(user_type == "member") %>% 
  group_by(end_station_name) %>% 
  summarize(count=n()) %>% 
  arrange(-count) %>% top_n(10) %>%
  mutate(end_station_name= fct_reorder(end_station_name, count)) %>% 
  ggplot(aes(x=end_station_name, y=count, fill=count)) +
  geom_bar(stat = "identity") + coord_flip() + scale_fill_gradient(low="blue", high="red") +
  labs(x="Ending Station Name", y="No of rides", title="Top 10 ending stations for member riders")
# key takeaways
# most popular starting and ending stations for casual and member riders are the same
```


### Bike start/end stations based on most round trips taken
```{r}
bike_rides %>%
  group_by(start_station_name, end_station_name) %>%
  filter(start_station_name!="NULL") %>%
  summarize(count=n()) %>% ungroup %>%
  arrange(-count) %>% top_n(10)
# Key takeaways
# Streeter Dr & Grand Ave has the most round trips taken by users with more than 10,000 rides
# Ellis Ave & 60th St to University Ave & 57th St has the second most round trips, could entail that students taking these rides
```

## Map analysis
Let's now do analysis based on map and coordinates in order to see location based rides
```{r}
chicago.lines <- bike_rides %>% filter(start_lng != end_lng & start_lat != end_lat) %>%
  group_by(user_type,
           bike_type,
           start_station_id,
           start_lng,
           start_lat,
           end_lng,
           end_lat,
           start_station_name,
           end_station_name) %>%
  summarize(rides = n(),.groups="drop") %>%
  filter(rides > 100)
# creating 2 data frames based on usertype only
casuals <- chicago.lines %>% filter(user_type == "casual")
members <- chicago.lines %>% filter(user_type == "member")

# setting coordinates data and fetching stamen map for visualization
chicago <- c(left = -87.8, 
                             bottom = 41.8, 
                             right = -87.6, 
                             top = 42.1)
chicago_map <- get_stamenmap(bbox = chicago, maptype = "terrain", zoom = 12)
```


### Visualising ride activity in chicago map for casual riders
```{r}
ggmap(chicago_map) + 
  geom_point(casuals, mapping=aes(x=start_lng,y=start_lat,color=bike_type),size=2)+
  coord_fixed(.7) + 
  xlab('')+ylab('') +
  ggtitle("Ride activity by casual riders")
## Key takeaways
# casual riders had most rides near the shore or bay area, implying that tourists are using them
```


### Visualising ride activity for member riders in chicago map
```{r}
ggmap(chicago_map,darken = c(0.1)) + 
  geom_point(members, mapping=aes(x=start_lng,y=start_lat,color=bike_type),size=2)+
  coord_fixed(.7) + 
  xlab('')+ylab('') +
  ggtitle("Ride activity by member riders")
## Key takeaways
# member riders are more spread out in the city, could imply that they take rides for work travel purposes
```
# Share and Act
**Key tasks**

1. Determine the best way to share your findings.
2. Create effective data visualizations.
3. Present your findings.
4. Ensure your work is accessible.

**Deliverable**

Supporting visualizations and key findings

*This phase showing key findings and top recommendations alongside further visualizations in dashboard is done in Tableau public*

Link to Tableau public dashboard :
[link](https://public.tableau.com/app/profile/muzzammil.khan/viz/Cyclisticbike-share_16794990478630/Story1)

## Exporting the dataframe
It is time to export and store our cleaned data for further analysis in Tableau
```{r }
write.csv(bike_rides, "bike_rides.csv")
# i will drop few columns that are not needed because of tableau public file size limit
drop_1 <- c("end_lat", "end_lng", "End_Month","End_Yr", "End_Day", "started_at", "ended_at", "ride_length_hour")
bike_rides_1 <- bike_rides[ , !(names(bike_rides) %in% drop_1)]
write.csv(bike_rides_1, "bike_rides_drop.csv")
```



